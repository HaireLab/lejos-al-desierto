---
title: "Data Assembly for Site Selection"
author: "S. Haire"
date: "2023-09-06"
output: html_document
df_print: knitr::kable
---

#### The code documents main steps for data assembly needed prior to identification of candidate points for site selection. Running the code requires download and further preparation of data layers. See README for more information.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(raster)
library(sf)
library(tidyr)
library(dplyr)
library(readr)
library(units)

fedpath<-"./data/fedlands/"
mtbspath1<-"./data/MTBS/"
usmxfirepath<-"./data/fireperims.updated/"
fires22path<-"./data/fireperims_region3"
climatepath<-"./data/"
eco3path<-"./data/"


```
## 1. Read in the study area polygons and the fire data. Recalcuate polygon area and add 2022 fires to the other datasets

```{r dataprep1, include=FALSE}
eco3<-read_sf(paste(eco3path, "Final_CASC_studyarea.shp", sep=""))
eco3xy<-st_zm(eco3) # drop z dim or nothing works...
## transform to crs of climate velocity
bioprj<-"+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
eco3_tr<-st_transform(eco3xy, bioprj)

## fire perims
## revised perims (added 3 fires by MLV)
perims<-read_sf(paste(usmxfirepath, "Sky_island_fire_polys_1985_2017_edits4transects.shp", sep=""))
areasi<-drop_units(st_area(perims)) / 10000 # m^2 to ha
perims2<-cbind(perims, areasi)
## MTBS perims for US
mtbsperims<-read_sf(paste(mtbspath1, "MTBS_CASCeco_to_2021.shp", sep=""))
areamtbs<-drop_units(st_area(mtbsperims)) / 10000 # m^2 to ha
mtbsperims2<-cbind(mtbsperims, areamtbs)
mtbs_tr<-st_transform(mtbsperims2, bioprj)

```

## 2. Read in and prepare climate data and ownership data: the forward climate velocity layer and principal component rasters and federal lands polygons. Subset ownership data to areas of interest. 

```{r dataprep2, include=FALSE}
## forward climate velocity, masked and/or cropped to the study region
fcv<-raster(paste(climatepath, "fcvcrop.tif", sep=""))
fcvmask<-raster(paste(climatepath,"fcvmask.tif", sep="")) 

## new pc's for the study region
pc1<-raster(paste(climatepath, "PC1_v2.tif", sep=""))
pc2<-raster(paste(climatepath, "PC2_v2.tif", sep=""))
pc_stack<-stack(pc1, pc2)

## ownership
## select the NPS and USFS polys 
fed<-read_sf(paste(fedpath, "fedlanp010g.shp", sep=""))
eco_fed<-st_transform(eco3xy, crs=4269)
fed_aznm<- dplyr::filter(fed, STATE=="AZ" | STATE=="NM" | STATE=="NM-AZ")
fedprj<-st_crs(fed_aznm)

## narrow down to areas of interest
aznm_fsnps<-fed_aznm %>% dplyr::filter(ADMIN1=="FS" | ADMIN1=="NPS")
aznm_other<-fed_aznm %>% dplyr::filter(GNIS_Name1=="Rincon Mountain Wilderness" | GNIS_Name1=="Fort Huachuca Military Reservation") # 2
aznm_combo<-rbind(aznm_fsnps, aznm_other) ## 168

```

## 3. Assemble points and attributes by first extracting values and coordinates for all raster cells in the 1-km forward climate velocity data layer. Sample climate data at these points, then join with 1) onwership polygons identified, above and 2) fire datasets. 

```{r dataassembly, include=FALSE}

fcv_xy<-coordinates(fcvmask, spatial=TRUE)
fcv_sf<-st_as_sf(fcv_xy) #678895 pts

## sample fcv and pcs
fcv.ex<-raster::extract(fcvmask, as_Spatial(fcv_sf), df=TRUE)
pc.ex<-raster::extract(pc_stack, as_Spatial(fcv_sf), df=TRUE)
climdat<-cbind(fcv.ex, pc.ex, fcv_sf)
climdat2<-climdat[!is.na(climdat$fcvmask),]
climdatpts<-st_as_sf(climdat2) ##### 200445

## add attributes to the fcv points#########
## ecoregion
climdatpts_eco<-st_join(climdatpts, eco3_tr)

aznm_combo2<-st_transform(aznm_combo, bioprj)
climpts_owneco<-st_join(climdatpts_eco, aznm_combo2) %>%
  drop_na(PERIMETER) %>% 
  mutate(unique_id=c(1:60300), .before=geometry) ## 60300 pts
```

```{r firesummary, include=FALSE}

# parse the year from Ig_Date...use laea
mtbsperimsyr<-mtbs_tr %>% mutate(fireyear=lubridate::year(Ig_Date))
## use st_join resulting in tibble
climptsf<-st_transform(climpts_owneco, crs=st_crs(mtbsperimsyr)) ## 60300
climpts3attr<-st_join(climptsf, mtbsperimsyr) ## 66343 

# get the max ha for each pt and the number of times burned
cpts_dat<-climpts3attr %>% st_drop_geometry() %>%
  group_by(unique_id) %>% 
  dplyr::summarize(n=n(), maxhectares=max(areamtbs), fireyear2=max(fireyear)) 
## join with original data
cpts_fires<-cbind(climptsf, cpts_dat) # 60300

dat2<-dat%>% dplyr::select(c(1:8,10, 13:15, 17:19))
names(dat2)[c(14,15)]<-c("timesburned", "geometry")
## change 1 to 0 where ha = na for times burned
dat2[is.na(dat2$maxhectares),14]<-0
## change nas in ha col to zero

## Bin the data across the gradient in forward climate velocity.

```

```{r fcvbins}

x<-climpts3attr
x2<-x %>% #st_drop_geometry() %>% # keep geom for now
  rename(fcv=fcvmask, pc1=PC1_v2, pc2=PC2_v2, mountain_eco=Complex_Na, objectid=OBJECTID, state=STATE, timesburned=tb,
         mostrecentyear=recntyr, maxfiresize=maxsize)

## eliminate NPS except Chiricahua NM
## keep na's--these are mx pts 
## includes sampled points on "Ceniza" and "Purica" that fall off island
## and one pt on the rim (delete below)
#x3<-x2 %>%
#mutate(across(c(mountain_eco, GNIS_Name1, state), ~ replace(., is.na(.), "Mexico")))
## use this file to get the gnis names to keep
tempnames<-read_csv("./data/point_attributes.csv")
u_keep<-c(unique(tempnames$GNIS_Name1), NA) ## na's in previous vers = Mexico
x3<-x2 %>% dplyr::filter(GNIS_Name1 %in% u_keep) ## 62141
#x3 %>% group_by(GNIS_Name1) %>% summarise(count=n()) #53
                      ## should drop geom first!!
## now try changing na's...
x4<-x3 %>%
mutate(across(c(mountain_eco, GNIS_Name1, state), ~ replace(., is.na(.), "Mexico")))

## classify the random points into 12 bins
x_bin<-x4 %>% mutate(bin = ntile(fcv, 12))
ggboxplot(x_bin, x="bin", y="fcv") # this one has very small diff in fcv btwn bins
## another option...use this one
## makes n groups with equal range
#x_bin2<-x4 %>% mutate(bin = cut_interval(fcv, n = 12)) # only gives 10
x_bin2<-x4 %>% mutate(bin = cut_interval(fcv, n = 10))
x_bin2_df<-x_bin2 %>% st_drop_geometry()
#write_csv(x_bin2_df, "./data/group_df.csv")
#
## summarise mtbs fires and then 2022 fires separately
burn_01_mtbs<-fcv_bins %>% mutate(in_perim = lengths(st_within(fcv_bins, mtbs_tr)))
burn_2022_over<-over(as_Spatial(burn_01_mtbs), as_Spatial(fires22u))
fcvbins_firedat<-cbind(burn_01_mtbs, burn_2022_over)
fcvbins_firedat[is.na(fcvbins_firedat$burn_2022_over),16]<-0
fcvbins_firedat$fireallyears<-fcvbins_firedat$in_perim + fcvbins_firedat$burn_2022_over
st_write(fcvbins_firedat, "./data/fcvbins_fireallyears.shp")

# 2022 fires
## this code only runs on ubuntu, not windows due to differences
## in the purr map function for reading files
homedir<-getwd()
setwd(fires22path)
fires22<-list.files('.', pattern="*kmz") %>%
      map(~sf::st_read(., layer="2022"))
fires22all<-bind_rows(fires22) #140 records
fires22xyall<-st_zm(fires22all) # drop z dim 
fires22b<-fires22xyall %>% dplyr::select(Name, geometry)
fires22_tr<-st_transform(fires22b, crs=bioprj)
## combine into one multipolygon feature set
fires22u<-st_union(fires22_tr)
setwd(homedir)
st_write(fires22u, "./data/fires_2022_region3.shp", append=FALSE)

```

```{r subregiondata}
 #these are the output files:
#  all_si_pts.shp
#all_az_pts.shp
#all_nm_pts.shp

```

## Maps of the candidate points and attributes
![Center points (red) for each 1-km raster cell that fall within accessible areas and previously sampled points (yellow). Burned areas (pink) are overlaid on elevation gradient (yellow to green).](plots/pinaleno_allpts.png)
![Center points (red) for each 1-km raster cell that fall within accessible areas and previously sampled points (black), overlaid on forward climate velocity gradient (yellow to orange)](plots/pinaleno_allpts_fcv.png)
![Center points (gold) for each 1-km raster cell that fall within accessible areas and previously sampled points (black).](plots/three_eco_pc1_pts2.png)
